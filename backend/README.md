# Multi-modal Search Backend

This project is a simplified Flask backend for a multi-modal search engine. It provides APIs for uploading files, background processing, semantic search, and summarization using Qdrant and Ollama models.

## Setup

1. Create a Python virtual environment and install dependencies:
   ```bash
   python -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```
2. Copy `.env.example` to `.env` and adjust settings.
3. Run the application:
   ```bash
   python run.py
   ```
This will start the Flask development server and create database tables automatically.

Logs are written to the file specified by the `LOG_FILE` environment variable (default `app.log`).

## Sample cURL Requests

An example script with `curl` commands for every API endpoint is provided in
`api_examples.sh`. Set `BASE_URL` to the address of the running Flask server and
execute the script to test the API:

```bash
bash api_examples.sh
```

Edit the file paths or IDs in the script as needed for your environment.

## Summarization

The search API now returns a `summary` field generated by the `llama3.2:3b` model. The summary provides a short inference over the search results relevant to the given query.
